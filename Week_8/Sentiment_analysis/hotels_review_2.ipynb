{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hotels Review part 2\n",
    "## Filtering & Sentiment Analysis Operations\n",
    "As you've probably noticed, the dataset has a few issues. Some columns are filled with useless information, others seem incorrect. If they are correct, it's unclear how they were calculated, and answers cannot be independently verified by your own calculations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: a bit more data processing\n",
    "Clean the data just a bit more. Add columns that will be useful later, change the values in other columns, and drop certain columns completely.\n",
    "\n",
    "- Initial column processing\n",
    "\n",
    "1. Drop lat and lng\n",
    "\n",
    "2. Replace Hotel_Address values with the following values (if the address contains the same of the city and the country, change it to just the city and the country).\n",
    "\n",
    "These are the only cities and countries in the dataset:\n",
    "\n",
    "Amsterdam, Netherlands\n",
    "\n",
    "Barcelona, Spain\n",
    "\n",
    "London, United Kingdom\n",
    "\n",
    "Milan, Italy\n",
    "\n",
    "Paris, France\n",
    "\n",
    "Vienna, Austria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data file now, this could take a while depending on file size\n",
      "Loading took 25.66 seconds\n"
     ]
    }
   ],
   "source": [
    "# Load the hotel reviews from CSV\n",
    "import pandas as pd\n",
    "import time\n",
    "# importing time so the start and end time can be used to calculate file loading time\n",
    "print(\"Loading data file now, this could take a while depending on file size\")\n",
    "start = time.time()\n",
    "# df is 'DataFrame' - make sure you downloaded the file to the data folder\n",
    "df = pd.read_csv(\"C:/Users/hp/Desktop/Data/Hotel_Reviews.csv\")\n",
    "end = time.time()\n",
    "print(\"Loading took \" + str(round(end - start, 2)) + \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London, United Kingdom    262301\n",
      "Barcelona, Spain           60149\n",
      "Paris, France              59928\n",
      "Amsterdam, Netherlands     57214\n",
      "Vienna, Austria            38939\n",
      "Milan, Italy               37207\n",
      "Name: Hotel_Address, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def replace_address(row):\n",
    "    if \"Netherlands\" in row[\"Hotel_Address\"]:\n",
    "        return \"Amsterdam, Netherlands\"\n",
    "    elif \"Barcelona\" in row[\"Hotel_Address\"]:\n",
    "        return \"Barcelona, Spain\"\n",
    "    elif \"United Kingdom\" in row[\"Hotel_Address\"]:\n",
    "        return \"London, United Kingdom\"\n",
    "    elif \"Milan\" in row[\"Hotel_Address\"]:        \n",
    "        return \"Milan, Italy\"\n",
    "    elif \"France\" in row[\"Hotel_Address\"]:\n",
    "        return \"Paris, France\"\n",
    "    elif \"Vienna\" in row[\"Hotel_Address\"]:\n",
    "        return \"Vienna, Austria\" \n",
    "\n",
    "# Replace all the addresses with a shortened, more useful form\n",
    "df[\"Hotel_Address\"] = df.apply(replace_address, axis = 1)\n",
    "# The sum of the value_counts() should add up to the total number of reviews\n",
    "print(df[\"Hotel_Address\"].value_counts())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can query country level data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_Name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hotel_Address</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Amsterdam, Netherlands</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Barcelona, Spain</th>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>London, United Kingdom</th>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Milan, Italy</th>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Paris, France</th>\n",
       "      <td>458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vienna, Austria</th>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Hotel_Name\n",
       "Hotel_Address                     \n",
       "Amsterdam, Netherlands         105\n",
       "Barcelona, Spain               211\n",
       "London, United Kingdom         400\n",
       "Milan, Italy                   162\n",
       "Paris, France                  458\n",
       "Vienna, Austria                158"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.groupby(\"Hotel_Address\").agg({\"Hotel_Name\": \"nunique\"}))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Process Hotel Meta-review columns\n",
    "\n",
    "- Drop Additional_Number_of_Scoring\n",
    "\n",
    "- Replace Total_Number_of_Reviews with the total number of reviews for that hotel that are actually in the dataset\n",
    "\n",
    "- Replace Average_Score with our own calculated score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop `Additional_Number_of_Scoring`\n",
    "#df.drop([\"Additional_Number_of_Scoring\"], axis = 1, inplace=True)\n",
    "# Replace `Total_Number_of_Reviews` and `Average_Score` with our own calculated values\n",
    "#df.Total_Number_of_Reviews = df.groupby('Hotel_Name').transform('count')\n",
    "df.Average_Score = round(df.groupby('Hotel_Name').Reviewer_Score.transform('mean'), 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Process review columns\n",
    "\n",
    "1. Drop Review_Total_Negative_Word_Counts, Review_Total_Positive_Word_Counts, Review_Date and days_since_review\n",
    "2. Keep Reviewer_Score, Negative_Review, and Positive_Review as they are,\n",
    "\n",
    "3. Keep Tags for now\n",
    "\n",
    "We'll be doing some additional filtering operations on the tags in the next section and then tags will be dropped\n",
    "\n",
    "- Process reviewer columns\n",
    "\n",
    "- Drop Total_Number_of_Reviews_Reviewer_Has_Given\n",
    "\n",
    "- Keep Reviewer_Nationality\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tag columns\n",
    "The Tag column is problematic as it is a list (in text form) stored in the column. Unfortunately the order and number of sub sections in this column are not always the same. It's hard for a human to identify the correct phrases to be interested in, because there are 515,000 rows, and 1427 hotels, and each has slightly different options a reviewer could choose. This is where NLP shines. You can scan the text and find the most common phrases, and count them\n",
    "# Filtering tags\n",
    "Remember that the goal of the dataset is to add sentiment and columns that will help you choose the best hotel (for yourself or maybe a client tasking you to make a hotel recommendation bot). You need to ask yourself if the tags are useful or not in the final dataset. Here is one interpretation (if you needed the dataset for other reasons different tags might stay in/out of the selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove opening and closing brackets\n",
    "df.Tags = df.Tags.str.strip(\"[']\")\n",
    "# remove all quotes too\n",
    "df.Tags = df.Tags.str.replace(\" ', '\", \",\", regex = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the length of stay tags\n",
    "Removing these tags is step 1, it reduces the total number of tags to be considered slightly. Note you do not remove them from the dataset, just choose to remove them from consideration as values to count/keep in the reviews dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the Tags into new columns\n",
    "# The file Hotel_Reviews_Tags.py, identifies the most important tags\n",
    "# Leisure trip, Couple, Solo traveler, Business trip, Group combined with Travelers with friends, \n",
    "# Family with young children, Family with older children, With a pet\n",
    "df[\"Leisure_trip\"] = df.Tags.apply(lambda tag: 1 if \"Leisure trip\" in tag else 0)\n",
    "df[\"Couple\"] = df.Tags.apply(lambda tag: 1 if \"Couple\" in tag else 0)\n",
    "df[\"Solo_traveler\"] = df.Tags.apply(lambda tag: 1 if \"Solo traveler\" in tag else 0)\n",
    "df[\"Business_trip\"] = df.Tags.apply(lambda tag: 1 if \"Business trip\" in tag else 0)\n",
    "df[\"Group\"] = df.Tags.apply(lambda tag: 1 if \"Group\" in tag or \"Travelers with friends\" in tag else 0)\n",
    "df[\"Family_with_young_children\"] = df.Tags.apply(lambda tag: 1 if \"Family with young children\" in tag else 0)\n",
    "df[\"Family_with_older_children\"] = df.Tags.apply(lambda tag: 1 if \"Family with older children\" in tag else 0)\n",
    "df[\"With_a_pet\"] = df.Tags.apply(lambda tag: 1 if \"With a pet\" in tag else 0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your file\n",
    "Finally, save the dataset as it is now with a new name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to Hotel_Reviews_Filtered.csv\n"
     ]
    }
   ],
   "source": [
    "df.drop([\"Review_Total_Negative_Word_Counts\", \"Review_Total_Positive_Word_Counts\", \"days_since_review\", \"Total_Number_of_Reviews_Reviewer_Has_Given\"], axis = 1, inplace=True)\n",
    "\n",
    "# Saving new data file with calculated columns\n",
    "print(\"Saving results to Hotel_Reviews_Filtered.csv\")\n",
    "df.to_csv('Hotel_Reviews_Filtered.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sentiment Analysis Operations\n",
    "In this final section, you will apply sentiment analysis to the review columns and save the results in a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to Hotel_Reviews_NLP.csv\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import nltk as nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "# Load the filtered hotel reviews from CSV\n",
    "df = pd.read_csv('Hotel_Reviews_Filtered.csv')\n",
    "\n",
    "# You code will be added here\n",
    "\n",
    "\n",
    "# Finally remember to save the hotel reviews with new NLP data added\n",
    "print(\"Saving results to Hotel_Reviews_NLP.csv\")\n",
    "df.to_csv('Hotel_Reviews_NLP.csv', index = False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing stop words\n",
    "If you were to run Sentiment Analysis on the Negative and Positive review columns, it could take a long time. Tested on a powerful test laptop with fast CPU,it took 12 - 14 minutes depending on which sentiment library was used. That's a (relatively) long time, so worth investigating if that can be speeded up.\n",
    "\n",
    "Removing stop words, or common English words that do not change the sentiment of a sentence, is the first step. By removing them, the sentiment analysis should run faster, but not be less accurate (as the stop words do not affect sentiment, but they do slow down the analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "#from nltk.corpus import stopwords\n",
    "\n",
    "# Load the hotel reviews from CSV\n",
    "df = pd.read_csv(\"Hotel_Reviews_Filtered.csv\")\n",
    "\n",
    "# Remove stop words - can be slow for a lot of text!\n",
    "# Ryan Han (ryanxjhan on Kaggle) has a great post measuring performance of different stop words removal approaches\n",
    "# https://www.kaggle.com/ryanxjhan/fast-stop-words-removal # using the approach that Ryan recommends\n",
    "start = time.time()\n",
    "cache = set(stopwords.words(\"english\"))\n",
    "def remove_stopwords(review):\n",
    "    text = \" \".join([word for word in review.split() if word not in cache])\n",
    "    return text\n",
    "\n",
    "# Remove the stop words from both columns\n",
    "df.Negative_Review = df.Negative_Review.apply(remove_stopwords)   \n",
    "df.Positive_Review = df.Positive_Review.apply(remove_stopwords)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing sentiment analysis\n",
    "Now you should calculate the sentiment analysis for both negative and positive review columns, and store the result in 2 new columns. The test of the sentiment will be to compare it to the reviewer's score for the same review. For instance, if the sentiment thinks the negative review had a sentiment of 1 (extremely positive sentiment) and a positive review sentiment of 1, but the reviewer gave the hotel the lowest score possible, then either the review text doesn't match the score, or the sentiment analyser could not recognize the sentiment correctly. You should expect some sentiment scores to be completely wrong, and often that will be explainable, e.g. the review could be extremely sarcastic \"Of course I LOVED sleeping in a room with no heating\" and the sentiment analyser thinks that's positive sentiment, even though a human reading it would know it was sarcasm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Create the vader sentiment analyser (there are others in NLTK you can try too)\n",
    "vader_sentiment = SentimentIntensityAnalyzer()\n",
    "# Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.\n",
    "\n",
    "# There are 3 possibilities of input for a review:\n",
    "# It could be \"No Negative\", in which case, return 0\n",
    "# It could be \"No Positive\", in which case, return 0\n",
    "# It could be a review, in which case calculate the sentiment\n",
    "def calc_sentiment(review):    \n",
    "    if review == \"No Negative\" or review == \"No Positive\":\n",
    "        return 0\n",
    "    return vader_sentiment.polarity_scores(review)[\"compound\"]  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later in your program when you are ready to calculate sentiment, you can apply it to each review as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating sentiment columns for both positive and negative reviews\n",
      "Calculating sentiment took 274.79 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Add a negative sentiment and positive sentiment column\n",
    "print(\"Calculating sentiment columns for both positive and negative reviews\")\n",
    "start = time.time()\n",
    "df[\"Negative_Sentiment\"] = df.Negative_Review.apply(calc_sentiment)\n",
    "df[\"Positive_Sentiment\"] = df.Positive_Review.apply(calc_sentiment)\n",
    "end = time.time()\n",
    "print(\"Calculating sentiment took \" + str(round(end - start, 2)) + \" seconds\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This takes approximately 4m 35s seconds on my computer. If you want to print of the results and see if the sentiment matches the review:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          Negative_Review  Negative_Sentiment\n",
      "186584  So bad experience memories I hotel The first n...             -0.9920\n",
      "129503  First charged twice room booked booking second...             -0.9896\n",
      "307286  The staff Had bad experience even booking Janu...             -0.9889\n",
      "201953  Everything DO NOT STAY AT THIS HOTEL I never i...             -0.9886\n",
      "452092  No WLAN room Incredibly rude restaurant staff ...             -0.9884\n",
      "...                                                   ...                 ...\n",
      "138365  Wifi terribly slow I speed test network upload...              0.9938\n",
      "79215   I find anything hotel first I walked past hote...              0.9938\n",
      "278506  The property great location There bakery next ...              0.9945\n",
      "339189  Guys I like hotel I wish return next year Howe...              0.9948\n",
      "480509  I travel lot far visited countless number hote...              0.9957\n",
      "\n",
      "[515738 rows x 2 columns]\n",
      "                                          Positive_Review  Positive_Sentiment\n",
      "137893  Bathroom Shower We going stay twice hotel 2 ni...             -0.9820\n",
      "5839    I completely disappointed mad since reception ...             -0.9780\n",
      "64158   get everything extra internet parking breakfas...             -0.9751\n",
      "124178  I didnt like anythig Room small Asked upgrade ...             -0.9721\n",
      "489137  Very rude manager abusive staff reception Dirt...             -0.9703\n",
      "...                                                   ...                 ...\n",
      "417442  We celebrated wedding night Langham I commend ...              0.9985\n",
      "322920  From moment stepped doors Guesthouse Hotel sta...              0.9985\n",
      "132492  We arrived super cute boutique hotel area expl...              0.9987\n",
      "287419  When first arrived hotel staff incredibly frie...              0.9987\n",
      "179007  We went Andaz 40th birthday celebration This a...              0.9991\n",
      "\n",
      "[515738 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.sort_values(by=[\"Negative_Sentiment\"], ascending=True)\n",
    "print(df[[\"Negative_Review\", \"Negative_Sentiment\"]])\n",
    "df = df.sort_values(by=[\"Positive_Sentiment\"], ascending=True)\n",
    "print(df[[\"Positive_Review\", \"Positive_Sentiment\"]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very last thing to do with the file before using it in the challenge, is to save it! You should also consider reordering all your new columns so they are easy to work with (for a human, it's a cosmetic change)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results to Hotel_Reviews_NLP.csv\n"
     ]
    }
   ],
   "source": [
    "# Reorder the columns (This is cosmetic, but to make it easier to explore the data later)\n",
    "df = df.reindex([\"Hotel_Name\", \"Hotel_Address\", \"Total_Number_of_Reviews\", \"Average_Score\", \"Reviewer_Score\", \"Negative_Sentiment\", \"Positive_Sentiment\", \"Reviewer_Nationality\", \"Leisure_trip\", \"Couple\", \"Solo_traveler\", \"Business_trip\", \"Group\", \"Family_with_young_children\", \"Family_with_older_children\", \"With_a_pet\", \"Negative_Review\", \"Positive_Review\"], axis=1)\n",
    "\n",
    "print(\"Saving results to Hotel_Reviews_NLP.csv\")\n",
    "df.to_csv(\"Hotel_Reviews_NLP.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
